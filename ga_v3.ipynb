{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if gpu is using\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = keras.models.load_model('./alexnet-cifar10_origin.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weights\n",
    "theta = np.array(model.get_weights(), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return: Population[2]\n",
    "#     [0]: processed input\n",
    "#     [1]: processed weight\n",
    "def initPopulation(x, theta, n, input_mutation_scale, weight_mutation_scale):\n",
    "    processed_x = x[np.random.randint(len(x), size=n)] # randomly choose n inputs from x\n",
    "    processed_theta = theta\n",
    "\n",
    "    # input level\n",
    "    # save the mutated inputs to the GA object (i.e. self.input_x)\n",
    "    if input_mutation_scale != 0 and input_mutation_scale != None:\n",
    "        processed_x = (np.clip((processed_x/255 + np.random.standard_cauchy(processed_x.shape) * input_mutation_scale),0,1) * 255).astype(int)\n",
    "\n",
    "    # weight level\n",
    "    # save the mutated weights to the GA object (i.e. self.model_weights)\n",
    "    if weight_mutation_scale != 0 and weight_mutation_scale != None:\n",
    "        processed_theta = []\n",
    "        for layer_weight in theta:\n",
    "            processed_theta.append(layer_weight + np.random.standard_cauchy(layer_weight.shape) * weight_mutation_scale)\n",
    "\n",
    "        return [processed_x, processed_theta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = initPopulation(x_test[:10], theta, 100, 0.1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return: list of size = len(x)*number of layer\n",
    "def nanFitness(P, model, phi):\n",
    "    x = P[0] # n inputs chosen from dataset\n",
    "    \n",
    "    # compute immediate outputs from each layer\n",
    "    extractor = keras.Model(inputs=model.inputs, outputs=[layer.output for layer in model.layers])\n",
    "    features = extractor.predict(x)\n",
    "    \n",
    "    # flatten neurons in the last layer for each input\n",
    "    last_layer_outputs = features[-1].reshape((len(x), -1))\n",
    "    \n",
    "    # normalize neurons\n",
    "    normalized_outputs = last_layer_outputs/(np.amax(last_layer_outputs) - np.amin(last_layer_outputs))\n",
    "    \n",
    "    fitness_values = np.amax(normalized_outputs, axis=1) - np.amin(normalized_outputs, axis=1)\n",
    "    return fitness_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InconsistencyFunc:\n",
    "    def __init__(self, py_script, backends, model_path, input_path, save_paths):\n",
    "        self.py_script = py_script\n",
    "        self.backend_1, self.backend_2 = backends\n",
    "        self.model_path = model_path\n",
    "        self.input_path = input_path\n",
    "        self.save_path_1, self.save_path_2 = save_paths\n",
    "        self.cmd_1 = f'python {self.py_script} {self.backend_1} {self.model_path} {self.input_path} {self.save_path_1} '\n",
    "        self.cmd_2 = f'python {self.py_script} {self.backend_2} {self.model_path} {self.input_path} {self.save_path_2} '\n",
    "        \n",
    "    def backend_predicts(self, bkd_k, layer_idx):\n",
    "        if bkd_k == 1:\n",
    "            os.system(self.cmd_1 + str(layer_idx))\n",
    "        else:\n",
    "            os.system(self.cmd_2 + str(layer_idx))\n",
    "\n",
    "    def get_predictions(self, layer_idx):\n",
    "        p1 = Process(target=self.backend_predicts, args=(1, layer_idx))\n",
    "        p2 = Process(target=self.backend_predicts, args=(2, layer_idx))\n",
    "        \n",
    "        p1.start()\n",
    "        p2.start()\n",
    "        p1.join()\n",
    "        p2.join()\n",
    "        \n",
    "    def computeDiff(self, layer_idx=-1):\n",
    "        self.get_predictions(layer_idx)\n",
    "        \n",
    "        self.predictions_1 = np.load(self.save_path_1)\n",
    "        self.predictions_2 = np.load(self.save_path_2)\n",
    "        self.predictions_diff = self.predictions_2 - self.predictions_1\n",
    "        \n",
    "        self.output_distance = np.sum(np.sum(self.predictions_diff**2, axis=1)) / len(self.predictions_1)\n",
    "        \n",
    "        return self.output_distance\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"my_model.h5\"\n",
    "input_path = \"inputs.npy\"\n",
    "save_paths = ['save1.npy', 'save2.npy']\n",
    "py_script = \"get_predicts.py\"\n",
    "backends = ['theano', 'tensorflow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inconsistFitness(P, model, phis):\n",
    "    model_path = \"if_model.h5\"\n",
    "    model.save(model_path)\n",
    "    \n",
    "    input_path = \"if_inputs.npy\"\n",
    "    np.save(input_path, P[0])\n",
    "    \n",
    "    save_paths = ['if_output1.npy', 'if_output2.npy']\n",
    "    py_script = \"get_predicts.py\"\n",
    "    backends = phis\n",
    "    \n",
    "    incFunc = InconsistencyFunc(py_script, backends, model_path, input_path, save_paths)\n",
    "    return incFunc.computeDiff()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population: \n",
    "#     [0]: inputs\n",
    "#     [1]: weights\n",
    "# phi2 will not be used if nanFitness is used\n",
    "# Return: list of size = len(x)\n",
    "def computeFitness(P, model, fitness_func, phis):\n",
    "    if fitness_func == \"nan\":\n",
    "        return nanFitness(P, model, phis[0])\n",
    "    if fitness_func == \"inc\":\n",
    "        return inconsistFitness(P, model, phis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fit = computeFitness(P, model, 'nan', ['theano', 'tensorflow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(P, m, Fit):\n",
    "    x = P[0]\n",
    "    selected_index = np.argpartition(Fit, -m)[-m:]\n",
    "    selected_x = x[selected_index]\n",
    "    return selected_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_prime = select(P, 5, Fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectParents(P2):\n",
    "    x1, x2 = random.sample(list(P2), 2)\n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = selectParents(P_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return 1-D array with length=3072 (32*32*3)\n",
    "def crossover(x1, x2, r1):\n",
    "    x1_flatten = x1.flatten()\n",
    "    x2_flatten = x2.flatten()\n",
    "    \n",
    "    # inefficient way\n",
    "    x_prime = []\n",
    "    for i in range(len(x1_flatten)):\n",
    "        rp = random.random()\n",
    "        if rp > r1:\n",
    "            x_prime.append(x1_flatten[i])\n",
    "        else:\n",
    "            x_prime.append(x2_flatten[i])\n",
    "\n",
    "    # efficient way\n",
    "    # use numpy random generate random list\n",
    "    # ...\n",
    "    \n",
    "    return x_prime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prime = crossover(x1, x2, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(x_prime).reshape((32,32,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(x_prime, x_shape, mutation_scale):\n",
    "    x_prime_np = np.array(x_prime)\n",
    "    x_2prime=(np.clip((x_prime_np/255 + np.random.standard_cauchy(x_prime_np.shape) * mutation_scale),0,1) * 255).astype(int)\n",
    "    x_2prime = x_2prime.reshape(x_shape)\n",
    "    return x_2prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2prime = mutate(x_prime, (32,32,3), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_2prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkFailed(P_2prime, model):\n",
    "    x = P[0]\n",
    "    F = []\n",
    "    for i in x:\n",
    "        try:\n",
    "            f.predict(i)\n",
    "        except:\n",
    "            F.append(i)\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure parameters\n",
    "f = model     # A DNN\n",
    "theta = theta # Weights of the DNN\n",
    "x = x_test     # input to the DNN\n",
    "phi = \"tensorflow\"   # the targeted DL frameworks\n",
    "r1 = 0.5    # Crossover rate\n",
    "r2 = 0.1    # Mutation rate\n",
    "maxIter = 1    # Maximum iterations\n",
    "m = 5     # Number of selected parents\n",
    "n = len(x_test)\n",
    "\n",
    "\n",
    "# Algorithm starts\n",
    "def algo_1():\n",
    "    iteration = 0\n",
    "    F = {}      # A set of failed test casses\n",
    "    P = initPopulation(f, x, theta, \"input\", 0.1, 0.2)\n",
    "\n",
    "    while iteration < maxIter:\n",
    "        iteration += 1\n",
    "        Fit = computeFitness(P[0], model, \"nan\", phi, phi)\n",
    "        P_prime = select(P, m, Fit)\n",
    "        P_2prime = P_prime\n",
    "        while len(P_2prime) < n:\n",
    "            x1, x2 = selectParents(P_prime)\n",
    "            x_prime = crossover(x1, x2, r1)\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < r2:\n",
    "                x_2prime = mutate(x_prime, r2)\n",
    "                P_2prime = P_2prime.union(x_2prime)\n",
    "        X = checkFailed(P_2prime)\n",
    "        if X != {}:\n",
    "            F = F.union(X)\n",
    "\n",
    "            return F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = {}      # A set of failed test casses\n",
    "P = initPopulation(f, x, theta, \"input\", 0.1, 0.2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fit = computeFitness(P[0], model, \"nan\", phi, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(Fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_prime = select(P, m, Fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_2prime = list(np.expand_dims(P_prime, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "while len(P_2prime) < 10000:\n",
    "    x1, x2 = selectParents(P_prime)\n",
    "    x_prime = crossover(x1, x2, r1)\n",
    "    r = random.uniform(0, 1)\n",
    "    if r < r2:\n",
    "        x_2prime = mutate(x_prime, r2, x1.shape)\n",
    "        P_2prime.append(x_2prime)\n",
    "end_time = time.perf_counter()\n",
    "end_time-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_P = [P_2prime, P[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,D = checkFailed(new_P, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdb5c6f5eaa2a17ed3afdcccdfa066a85023e220ece0c7237533a765dc216f79"
  },
  "kernelspec": {
   "display_name": "tf_th",
   "language": "python",
   "name": "tf_th"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
