{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from multiprocessing import Process\n",
    "import redis\n",
    "import pickle\n",
    "import subprocess\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "redis_server_path = '/data/yylaiai/redis/redis-stable/src/redis-server'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x7f3680e49208>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open redis server on current jupyter notebook terminal\n",
    "subprocess.Popen([redis_server_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = keras.models.load_model('./alexnet-cifar10_origin.h5', compile=False) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA:\n",
    "    def __init__(self, fit, load_model, dataset, input_shape, init_input_mut, init_weight_mut, r1, r2, m, n, maxIter, db_flag):\n",
    "        self.fitness_func, self.phi = fit # a tuple: (fitness function, list of DL framework(s) to be used)\n",
    "        self.model = load_model()\n",
    "        self.dataset = dataset\n",
    "        self.input_shape = input_shape\n",
    "        self.init_input_mut = init_input_mut\n",
    "        self.init_weight_mut = init_weight_mut\n",
    "        self.r1 = r1\n",
    "        self.r2 = r2\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.maxIter = maxIter\n",
    "        self.db_flag = db_flag\n",
    "        self.redis = redis.Redis(db=db_flag)\n",
    "        \n",
    "    def initPopulation(self):\n",
    "        # randomly choose n inputs from the dataset if n < len(dataset)\n",
    "        if len(self.dataset) > self.n:\n",
    "            selected_x = self.dataset[np.random.choice(len(self.dataset), size=self.n, replace=False)]\n",
    "        else:\n",
    "            selected_x = self.dataset\n",
    "            \n",
    "        # get model weights\n",
    "        original_weights = np.array(self.model.get_weights(), dtype=object)\n",
    "            \n",
    "        self.mutated_inputs = selected_x\n",
    "        self.mutated_weights = original_weights\n",
    "\n",
    "        # input level\n",
    "        if self.init_input_mut != 0 and self.init_input_mut != None:\n",
    "            self.mutated_inputs = (np.clip((selected_x/255 + np.random.standard_cauchy(selected_x.shape) * self.init_input_mut),0,1) * 255).astype(int)\n",
    "            \n",
    "        # weight level\n",
    "        # set the model weights of the GA object to the mutated weights\n",
    "        if self.init_weight_mut != 0 and self.init_weight_mut != None:\n",
    "            self.mutated_weights = []\n",
    "            for layer_weight in original_weights:\n",
    "                self.mutated_weights.append(layer_weight + np.random.standard_cauchy(layer_weight.shape) * self.init_weight_mut)\n",
    "            self.model.set_weights(self.mutated_weights)\n",
    "                \n",
    "        return [self.mutated_inputs, self.mutated_weights]\n",
    "\n",
    "\n",
    "    def computeFitness(self):\n",
    "        if self.fitness_func == \"inc\":\n",
    "            FFunc = InconsistencyFunc(\"get_predicts.py\", 0, self.redis, self.phi, self.model, self.mutated_inputs, -1)\n",
    "            self.fitness_values = FFunc.compute()\n",
    "            return self.fitness_values\n",
    "        elif self.fitness_func == \"nan\":\n",
    "            FFunc = NanFunc(\"get_predicts.py\", 0, self.redis, self.phi, self.model, self.mutated_inputs, -1)\n",
    "            self.fitness_values = FFunc.compute()\n",
    "            return self.fitness_values\n",
    "        \n",
    "    def topK_fitness(self, k):\n",
    "        return self.fitness_values[np.argpartition(self.fitness_values, -k)[-k:]]\n",
    "        \n",
    "        \n",
    "    # select m candidates for parents of next-generation inputs\n",
    "    def select(self):\n",
    "        selected_index = np.argpartition(self.fitness_values, -self.m)[-self.m:]\n",
    "        self.selected_x = self.mutated_inputs[selected_index]\n",
    "        return self.selected_x\n",
    "    \n",
    "    # select 2 parents from the candidates\n",
    "    def selectParents(self):\n",
    "        self.x1, self.x2 = random.sample(list(self.selected_x), 2)\n",
    "        return self.x1, self.x2\n",
    "    \n",
    "    # return a flatten list of a crossover product of the selected parents\n",
    "    def crossover(self):\n",
    "        x1_flatten = self.x1.flatten()\n",
    "        x2_flatten = self.x2.flatten()\n",
    "\n",
    "        x1_factor = np.random.choice(2, size=x1_flatten.shape, p=[0.5, 0.5])\n",
    "        x2_factor = 1 - a\n",
    "        \n",
    "        self.x_prime = x1_flatten * x1_factor + x2_flatten * x2_factor\n",
    "\n",
    "        return self.x_prime\n",
    "    \n",
    "    # mutate the crossover product and reshape it as the shape of the input instance\n",
    "    def mutate(self):\n",
    "        self.x_2prime=(np.clip((self.x_prime/255 + np.random.standard_cauchy(self.x_prime.shape) * self.r2),0,1) * 255).astype(int)\n",
    "        self.x_2prime = self.x_2prime.reshape(self.input_shape)\n",
    "        return self.x_2prime\n",
    "    \n",
    "    # check if the new DNN model can predict the mutated inputs without triggering error\n",
    "    def checkFailed(self):\n",
    "        try:\n",
    "            if self.fitness_func == \"inc\":\n",
    "                return []\n",
    "\n",
    "            elif self.fitness_func == \"nan\":\n",
    "                predictions = self.model.predict(self.mutated_inputs)\n",
    "                if np.nan(predictions).any(): # if there is any nan in the predictions\n",
    "                    return self.mutated_inputs\n",
    "        except Exception as e:\n",
    "            return [e]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InconsistencyFunc:\n",
    "    def __init__(self, py_script, db_flag, redis_server, backends, model, inputs, layer_idx):\n",
    "        self.redis_server = redis_server\n",
    "        self.db_flag = db_flag\n",
    "        \n",
    "        self.backend_1, self.backend_2 = backends\n",
    "        self.model = model\n",
    "        self.inputs = inputs\n",
    "        self.cmd_1 = f'python {py_script} {self.backend_1} {db_flag} {layer_idx}'\n",
    "        self.cmd_2 = f'python {py_script} {self.backend_2} {db_flag} {layer_idx}'\n",
    "    \n",
    "    def compute(self):\n",
    "        # store model and inputs\n",
    "        with self.redis_server.pipeline() as pipe:\n",
    "            pipe.mset({\"model\": pickle.dumps(self.model)})\n",
    "            pipe.mset({\"inputs\": pickle.dumps(self.inputs)})\n",
    "            pipe.execute()\n",
    "        \n",
    "        # run subprocess to get predictions\n",
    "        p1 = Process(target=lambda: os.system(self.cmd_1))\n",
    "        p2 = Process(target=lambda: os.system(self.cmd_2))\n",
    "        p1.start()\n",
    "        p2.start()\n",
    "        p1.join()\n",
    "        p2.join()\n",
    "        \n",
    "        # load predictions\n",
    "        with self.redis_server.pipeline() as pipe:\n",
    "            pipe.hget(f\"{self.backend_1}\", \"predictions\")\n",
    "            pipe.hget(f\"{self.backend_2}\", \"predictions\")\n",
    "            predictions = pipe.execute()\n",
    "        \n",
    "        self.predictions_1 = pickle.loads(predictions[0])\n",
    "        self.predictions_2 = pickle.loads(predictions[1])\n",
    "        \n",
    "        # compute fitness\n",
    "        predictions_diff = np.abs(self.predictions_2 - self.predictions_1)\n",
    "        \n",
    "        self.fitness_values = np.sum(predictions_diff**2, axis=1) / len(self.predictions_1)\n",
    "        \n",
    "        return self.fitness_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NanFunc:\n",
    "    def __init__(self, py_script, db_flag, redis_server, backend, model, inputs, layer_idx):\n",
    "        self.redis_server = redis_server\n",
    "        self.db_flag = db_flag\n",
    "        \n",
    "        self.model = model\n",
    "        self.inputs = inputs\n",
    "        self.backend = backend[0]\n",
    "        self.cmd = f'python {py_script} {self.backend} {db_flag} {layer_idx}'\n",
    "        \n",
    "    def compute(self):\n",
    "        # store model and inputs\n",
    "        with self.redis_server.pipeline() as pipe:\n",
    "            pipe.mset({\"model\": pickle.dumps(self.model)})\n",
    "            pipe.mset({\"inputs\": pickle.dumps(self.inputs)})\n",
    "            pipe.execute()\n",
    "        \n",
    "        # run subprocess to get predictions\n",
    "        os.system(self.cmd)\n",
    "        \n",
    "        # load predictions\n",
    "        self.predictions = pickle.loads(self.redis_server.hget(f\"{self.backend}\", \"predictions\"))\n",
    "        \n",
    "        # normalize neurons\n",
    "        normalized_outputs = self.predictions/(np.amax(self.predictions) - np.amin(self.predictions))\n",
    "        \n",
    "        # compute fitness\n",
    "        self.fitness_values = np.amax(normalized_outputs, axis=1) - np.amin(normalized_outputs, axis=1)\n",
    "        \n",
    "        return self.fitness_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ga_main(maxIter):\n",
    "    F = []\n",
    "    ga = GA((\"inc\", [\"tensorflow\", \"theano\"]), load_model, x_test[:100], x_test[0].shape, 0.1, 0, 0.5, 0.2, 5, 1000, 10, 0)\n",
    "    x, theta = ga.initPopulation()\n",
    "    for _ in range(maxIter):\n",
    "        Fit = ga.computeFitness()\n",
    "        P_prime = ga.select()\n",
    "        test_cases = []\n",
    "        test_cases.extend(P_prime)\n",
    "        while len(test_cases) < ga.n:\n",
    "            x1, x2 = ga.selectParents()\n",
    "            x_prime = ga.crossover()\n",
    "            r = random.uniform(0,1)\n",
    "            if r < ga.r2:\n",
    "                x_2prime = ga.mutate()\n",
    "                test_cases.append(x_2prime)\n",
    "\n",
    "        ga.mutated_inputs = np.array(test_cases)\n",
    "        X = ga.checkFailed()\n",
    "        if X != []:\n",
    "            F.extend(X)\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = ga_main(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GA((\"inc\", [\"tensorflow\", \"theano\"]), load_model, x_test[:100], x_test[0].shape, 0.1, 0, 0.5, 0.2, 5, 1000, 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, theta = ga.initPopulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fit = ga.computeFitness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_prime = ga.select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = []\n",
    "test_cases.extend(P_prime)\n",
    "while len(test_cases) < ga.n:\n",
    "    x1, x2 = ga.selectParents()\n",
    "    x_prime = ga.crossover()\n",
    "    r = random.uniform(0,1)\n",
    "    if r < ga.r2:\n",
    "        x_2prime = ga.mutate()\n",
    "        test_cases.append(x_2prime)\n",
    "        \n",
    "ga.mutated_inputs = np.array(test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ga.checkFailed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdb5c6f5eaa2a17ed3afdcccdfa066a85023e220ece0c7237533a765dc216f79"
  },
  "kernelspec": {
   "display_name": "tf_th",
   "language": "python",
   "name": "tf_th"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
